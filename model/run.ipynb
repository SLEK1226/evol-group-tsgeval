{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-04 10:42:39.956954: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-01-04 10:42:40.244791: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-01-04 10:42:40.251478: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda-12.3/lib64:/usr/local/nvidia/lib:/usr/local/nvidia/lib64\n",
      "2025-01-04 10:42:40.251506: I tensorflow/compiler/xla/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2025-01-04 10:42:47.214606: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda-12.3/lib64:/usr/local/nvidia/lib:/usr/local/nvidia/lib64\n",
      "2025-01-04 10:42:47.215250: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda-12.3/lib64:/usr/local/nvidia/lib:/usr/local/nvidia/lib64\n",
      "2025-01-04 10:42:47.215267: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "import logging\n",
    "import os\n",
    "import pickle\n",
    "import random\n",
    "import shutil\n",
    "import time\n",
    "\n",
    "# 3rd-Party Modules\n",
    "import numpy as np\n",
    "import torch\n",
    "import joblib\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Self-Written Modules\n",
    "from data.data_preprocess import data_preprocess\n",
    "from metrics.metric_utils import (\n",
    "    feature_prediction, one_step_ahead_prediction, reidentify_score\n",
    ")\n",
    "\n",
    "from models.timegan import TimeGAN\n",
    "from models.utils import timegan_trainer, timegan_generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Config:\n",
    "    def __init__(self):\n",
    "        self.device = 'cuda'\n",
    "        self.exp = 'test'\n",
    "        self.is_train = True\n",
    "        self.seed = 0\n",
    "        self.feat_pred_no = 2\n",
    "        self.max_seq_len = 100\n",
    "        self.train_rate = 0.5\n",
    "        self.emb_epochs = 600\n",
    "        self.sup_epochs = 600\n",
    "        self.gan_epochs = 600\n",
    "        self.batch_size = 128\n",
    "        self.hidden_dim = 20\n",
    "        self.num_layers = 3\n",
    "        self.dis_thresh = 0.15\n",
    "        self.optimizer = 'adam'\n",
    "        self.learning_rate = 1e-3\n",
    "\n",
    "args = Config()\n",
    "\n",
    "def str2bool(v):\n",
    "    if isinstance(v, bool):\n",
    "       return v\n",
    "    if v.lower() in ('yes', 'true', 't', 'y', '1'):\n",
    "        return True\n",
    "    elif v.lower() in ('no', 'false', 'f', 'n', '0'):\n",
    "        return False\n",
    "    else:\n",
    "        raise argparse.ArgumentTypeError('Boolean value expected.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Code directory:\t\t\t/h3cstore_ns/jcxie/zsl/timegan-pytorch-main\n",
      "Data directory:\t\t\t/h3cstore_ns/jcxie/zsl/timegan-pytorch-main/data\n",
      "Output directory:\t\t/h3cstore_ns/jcxie/zsl/timegan-pytorch-main/output/test\n",
      "TensorBoard directory:\t\t/h3cstore_ns/jcxie/zsl/timegan-pytorch-main/tensorboard\n",
      "\n",
      "Using CUDA\n",
      "\n",
      "Loading data...\n",
      "\n",
      "Dropped 504 rows (outliers)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3676/3676 [00:06<00:00, 593.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed data: (3676, 100, 6) (Idx x MaxSeqLen x Features)\n",
      "\n",
      "Original data preview:\n",
      "[[[ 0.19376718  0.19446839]\n",
      "  [ 0.19232369  0.19224311]\n",
      "  [ 0.19594256  0.19481357]\n",
      "  [ 0.20078938  0.20019403]\n",
      "  [ 0.19906535  0.20037676]\n",
      "  [ 0.19672326  0.19752207]\n",
      "  [ 0.19728439  0.19644191]\n",
      "  [-1.         -1.        ]\n",
      "  [-1.         -1.        ]\n",
      "  [-1.         -1.        ]]\n",
      "\n",
      " [[ 0.4860957   0.49640034]\n",
      "  [ 0.48522808  0.48878844]\n",
      "  [ 0.48351736  0.48673669]\n",
      "  [ 0.48463053  0.48547787]\n",
      "  [ 0.49108043  0.4905124 ]\n",
      "  [ 0.48256791  0.48940151]\n",
      "  [ 0.47696925  0.48430077]\n",
      "  [-1.         -1.        ]\n",
      "  [-1.         -1.        ]\n",
      "  [-1.         -1.        ]]]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "code_dir = os.path.abspath(\".\")\n",
    "if not os.path.exists(code_dir):\n",
    "    raise ValueError(f\"Code directory not found at {code_dir}.\")\n",
    "\n",
    "## Data directory\n",
    "data_path = os.path.abspath(\"./data\")\n",
    "if not os.path.exists(data_path):\n",
    "    raise ValueError(f\"Data file not found at {data_path}.\")\n",
    "data_dir = os.path.dirname(data_path)\n",
    "data_file_name = os.path.basename(data_path)\n",
    "\n",
    "## Output directories\n",
    "args.model_path = os.path.abspath(f\"./output/{args.exp}/\")\n",
    "out_dir = os.path.abspath(args.model_path)\n",
    "if not os.path.exists(out_dir):\n",
    "    os.makedirs(out_dir, exist_ok=True)\n",
    "\n",
    "# TensorBoard directory\n",
    "tensorboard_path = os.path.abspath(\"./tensorboard\")\n",
    "if not os.path.exists(tensorboard_path):\n",
    "    os.makedirs(tensorboard_path, exist_ok=True)\n",
    "\n",
    "print(f\"\\nCode directory:\\t\\t\\t{code_dir}\")\n",
    "print(f\"Data directory:\\t\\t\\t{data_path}\")\n",
    "print(f\"Output directory:\\t\\t{out_dir}\")\n",
    "print(f\"TensorBoard directory:\\t\\t{tensorboard_path}\\n\")\n",
    "\n",
    "\n",
    "os.environ['PYTHONHASHSEED'] = str(args.seed)\n",
    "random.seed(args.seed)\n",
    "np.random.seed(args.seed)\n",
    "torch.manual_seed(args.seed)\n",
    "\n",
    "if args.device == \"cuda\" and torch.cuda.is_available():\n",
    "    print(\"Using CUDA\\n\")\n",
    "    args.device = torch.device(\"cuda:0\")\n",
    "    # torch.cuda.manual_seed_all(args.seed)\n",
    "    torch.cuda.manual_seed(args.seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "else:\n",
    "    print(\"Using CPU\\n\")\n",
    "    args.device = torch.device(\"cpu\")\n",
    "\n",
    "\n",
    "data_path = \"data/stock.csv\"\n",
    "X, T, _, args.max_seq_len, args.padding_value = data_preprocess(\n",
    "    data_path, args.max_seq_len\n",
    ")\n",
    "\n",
    "print(f\"Processed data: {X.shape} (Idx x MaxSeqLen x Features)\\n\")\n",
    "print(f\"Original data preview:\\n{X[:2, :10, :2]}\\n\")\n",
    "\n",
    "args.feature_dim = X.shape[-1]\n",
    "args.Z_dim = X.shape[-1]\n",
    "\n",
    "\n",
    "train_data, test_data, train_time, test_time = train_test_split(\n",
    "    X, T, test_size=args.train_rate, random_state=args.seed\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Start Embedding Network Training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 599, Loss: 0.0011: 100%|██████████| 600/600 [02:15<00:00,  4.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Start Training with Supervised Loss Only\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 599, Loss: 0.0080: 100%|██████████| 600/600 [01:49<00:00,  5.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Start Joint Training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 599, E: 0.0971, G: 1.8348, D: 1.8551: 100%|██████████| 600/600 [18:44<00:00,  1.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Saved at path: /h3cstore_ns/jcxie/zsl/timegan-pytorch-main/output/test\n",
      "\n",
      "Generating Data...\n",
      "Generated data preview:\n",
      "[[[-1.0003532 -1.0001502]\n",
      "  [-1.0003532 -1.0001502]\n",
      "  [-1.0003532 -1.0001502]\n",
      "  [-1.0003532 -1.0001502]\n",
      "  [-1.0003532 -1.0001502]\n",
      "  [-1.0003532 -1.0001502]\n",
      "  [-1.0003532 -1.0001502]\n",
      "  [-1.0003532 -1.0001502]\n",
      "  [-1.0003532 -1.0001502]\n",
      "  [-1.0003532 -1.0001502]]\n",
      "\n",
      " [[-1.0003532 -1.0001502]\n",
      "  [-1.0003532 -1.0001502]\n",
      "  [-1.0003532 -1.0001502]\n",
      "  [-1.0003532 -1.0001502]\n",
      "  [-1.0003532 -1.0001502]\n",
      "  [-1.0003532 -1.0001502]\n",
      "  [-1.0003532 -1.0001502]\n",
      "  [-1.0003532 -1.0001502]\n",
      "  [-1.0003532 -1.0001502]\n",
      "  [-1.0003532 -1.0001502]]]\n",
      "\n",
      "Model Runtime: 23.00885624885559 mins\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "start = time.time()\n",
    "\n",
    "model = TimeGAN(args)\n",
    "if args.is_train == True:\n",
    "    timegan_trainer(model, train_data, train_time, args)\n",
    "generated_data = timegan_generator(model, train_time, args)\n",
    "generated_time = train_time\n",
    "\n",
    "\n",
    "end = time.time()\n",
    "\n",
    "print(f\"Generated data preview:\\n{generated_data[:2, -10:, :2]}\\n\")\n",
    "print(f\"Model Runtime: {(end - start)/60} mins\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running feature prediction using original data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 19, Loss: 0.2464: 100%|██████████| 20/20 [00:03<00:00,  6.28it/s]\n",
      "Epoch: 19, Loss: 2.6676: 100%|██████████| 20/20 [00:03<00:00,  6.21it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running feature prediction using generated data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 19, Loss: 0.0241: 100%|██████████| 20/20 [00:03<00:00,  6.28it/s]\n",
      "Epoch: 19, Loss: 0.0206: 100%|██████████| 20/20 [00:03<00:00,  6.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature prediction results:\n",
      "(1) Ori: [0.2955 0.239 ]\n",
      "(2) New: [0.1357 0.1448]\n",
      "\n",
      "Running one step ahead prediction using original data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 19, Loss: 0.4252: 100%|██████████| 20/20 [00:03<00:00,  6.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running one step ahead prediction using generated data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 19, Loss: 0.3763: 100%|██████████| 20/20 [00:03<00:00,  6.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "One step ahead prediction results:\n",
      "(1) Ori: 0.3261\n",
      "(2) New: 0.3078\n",
      "\n",
      "Total Runtime: 23.721916536490124 mins\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with open(f\"{args.model_path}/train_data.pickle\", \"wb\") as fb:\n",
    "    pickle.dump(train_data, fb)\n",
    "with open(f\"{args.model_path}/train_time.pickle\", \"wb\") as fb:\n",
    "    pickle.dump(train_time, fb)\n",
    "with open(f\"{args.model_path}/test_data.pickle\", \"wb\") as fb:\n",
    "    pickle.dump(test_data, fb)\n",
    "with open(f\"{args.model_path}/test_time.pickle\", \"wb\") as fb:\n",
    "    pickle.dump(test_time, fb)\n",
    "with open(f\"{args.model_path}/fake_data.pickle\", \"wb\") as fb:\n",
    "    pickle.dump(generated_data, fb)\n",
    "with open(f\"{args.model_path}/fake_time.pickle\", \"wb\") as fb:\n",
    "    pickle.dump(generated_time, fb)\n",
    "\n",
    "\n",
    "\n",
    "# Define enlarge data and its labels\n",
    "enlarge_data = np.concatenate((train_data, test_data), axis=0)\n",
    "enlarge_time = np.concatenate((train_time, test_time), axis=0)\n",
    "enlarge_data_label = np.concatenate((np.ones([train_data.shape[0], 1]), np.zeros([test_data.shape[0], 1])), axis=0)\n",
    "\n",
    "# Mix the order\n",
    "idx = np.random.permutation(enlarge_data.shape[0])\n",
    "enlarge_data = enlarge_data[idx]\n",
    "enlarge_data_label = enlarge_data_label[idx]\n",
    "\n",
    "\n",
    "\n",
    "# 1. Feature prediction\n",
    "feat_idx = np.random.permutation(train_data.shape[2])[:args.feat_pred_no]\n",
    "print(\"Running feature prediction using original data...\")\n",
    "ori_feat_pred_perf = feature_prediction(\n",
    "    (train_data, train_time), \n",
    "    (test_data, test_time),\n",
    "    feat_idx\n",
    ")\n",
    "print(\"Running feature prediction using generated data...\")\n",
    "new_feat_pred_perf = feature_prediction(\n",
    "    (generated_data, generated_time),\n",
    "    (test_data, test_time),\n",
    "    feat_idx\n",
    ")\n",
    "\n",
    "feat_pred = [ori_feat_pred_perf, new_feat_pred_perf]\n",
    "\n",
    "print('Feature prediction results:\\n' +\n",
    "        f'(1) Ori: {str(np.round(ori_feat_pred_perf, 4))}\\n' +\n",
    "        f'(2) New: {str(np.round(new_feat_pred_perf, 4))}\\n')\n",
    "\n",
    "# 2. One step ahead prediction\n",
    "print(\"Running one step ahead prediction using original data...\")\n",
    "ori_step_ahead_pred_perf = one_step_ahead_prediction(\n",
    "    (train_data, train_time), \n",
    "    (test_data, test_time)\n",
    ")\n",
    "print(\"Running one step ahead prediction using generated data...\")\n",
    "new_step_ahead_pred_perf = one_step_ahead_prediction(\n",
    "    (generated_data, generated_time),\n",
    "    (test_data, test_time)\n",
    ")\n",
    "\n",
    "step_ahead_pred = [ori_step_ahead_pred_perf, new_step_ahead_pred_perf]\n",
    "\n",
    "print('One step ahead prediction results:\\n' +\n",
    "        f'(1) Ori: {str(np.round(ori_step_ahead_pred_perf, 4))}\\n' +\n",
    "        f'(2) New: {str(np.round(new_step_ahead_pred_perf, 4))}\\n')\n",
    "\n",
    "print(f\"Total Runtime: {(time.time() - start)/60} mins\\n\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "condaenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
